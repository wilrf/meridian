---
title: "Pandas"
phase: 4
order: 2
requires: ["pandas"]
prev: "4.1_numpy"
next: "5.1_linear_regression"
---

# Lesson 2: pandas DataFrames

## The Problem

You have stock data: dates, prices, volumes, symbols. NumPy arrays are fast but unlabeled—which column is price? Which row is January 15th? You need a data structure that combines the speed of NumPy with the convenience of named rows and columns.

---

## The Metaphor

A **DataFrame** is like an **Excel spreadsheet**:
- Rows represent observations (each day's data)
- Columns represent variables (price, volume, etc.)
- Columns have names ("price", not "column 3")
- Rows have an index (dates, IDs, etc.)
- You can filter, sort, and calculate with formulas

But unlike Excel, pandas can handle millions of rows without slowing down.

---

## The Technical Reality

### pandas Architecture

```
DataFrame
├── Index (row labels)
├── Columns (column names)
└── Data (2D NumPy array underneath)

Series = single column with index
```

pandas is built on NumPy—DataFrames store data as NumPy arrays internally, giving you NumPy's speed with spreadsheet-like convenience.

---

## The Code

### Creating DataFrames

~~~python runnable
import pandas as pd
import numpy as np

# From dictionary (most common)
data = {
    "symbol": ["AAPL", "GOOGL", "MSFT"],
    "price": [175.50, 140.25, 380.00],
    "shares": [100, 50, 75]
}
df = pd.DataFrame(data)
#   symbol   price  shares
# 0   AAPL  175.50     100
# 1  GOOGL  140.25      50
# 2   MSFT  380.00      75

# From list of dictionaries (each dict = one row)
rows = [
    {"symbol": "AAPL", "price": 175.50},
    {"symbol": "GOOGL", "price": 140.25},
]
df = pd.DataFrame(rows)

# From NumPy array
arr = np.array([[1, 2], [3, 4], [5, 6]])
df = pd.DataFrame(arr, columns=["A", "B"])

# From CSV file
df = pd.read_csv("prices.csv")
df = pd.read_csv("prices.csv", index_col="date", parse_dates=True)

# From Excel
df = pd.read_excel("data.xlsx", sheet_name="Sheet1")
~~~

### Exploring DataFrames

~~~python runnable
# Quick overview
df.head()           # First 5 rows
df.tail(10)         # Last 10 rows
df.shape            # (rows, columns)
df.columns          # Column names
df.index            # Row labels
df.dtypes           # Data types of each column
df.info()           # Summary of DataFrame
df.describe()       # Statistics for numeric columns
~~~

### Selecting Data

~~~python runnable
# Select column (returns Series)
df["price"]         # Single column
df.price            # Same (attribute access, doesn't work for all names)

# Select multiple columns (returns DataFrame)
df[["symbol", "price"]]

# Select rows by index label
df.loc[0]                    # Row with index 0
df.loc[0:2]                  # Rows 0, 1, 2 (inclusive!)
df.loc[0, "price"]           # Specific cell
df.loc[0:2, ["symbol", "price"]]  # Rows 0-2, specific columns

# Select rows by position (like list indexing)
df.iloc[0]                   # First row
df.iloc[0:2]                 # First 2 rows (exclusive!)
df.iloc[0, 1]                # Row 0, column 1
df.iloc[0:3, 0:2]            # Rows 0-2, columns 0-1

# Boolean selection (filtering)
df[df["price"] > 150]        # Rows where price > 150
df[(df["price"] > 100) & (df["shares"] >= 50)]  # Multiple conditions
~~~

### Modifying DataFrames

~~~python runnable
# Add new column
df["value"] = df["price"] * df["shares"]

# Modify existing column
df["price"] = df["price"] * 1.1  # 10% increase

# Drop columns
df = df.drop(columns=["volume"])

# Drop rows
df = df.drop(index=[0, 2])       # Drop specific rows

# Rename columns
df = df.rename(columns={"price": "close_price"})

# Set index
df = df.set_index("symbol")
df = df.reset_index()            # Move index back to column
~~~

### Operations and Calculations

~~~python runnable
# Arithmetic (vectorized)
df["return"] = df["close"] / df["open"] - 1
df["log_return"] = np.log(df["close"] / df["open"])

# Apply function to column
df["symbol_lower"] = df["symbol"].apply(str.lower)
df["price_rounded"] = df["price"].apply(lambda x: round(x, 2))

# Apply function to row
df["total"] = df.apply(lambda row: row["price"] * row["shares"], axis=1)

# Aggregations
df["price"].sum()
df["price"].mean()
df["price"].std()
df["price"].min(), df["price"].max()
df["price"].quantile(0.5)        # Median
df["price"].cumsum()             # Cumulative sum
df["price"].pct_change()         # Percent change from previous row
~~~

### Grouping

~~~python runnable
# Group by single column
grouped = df.groupby("sector")

# Aggregations on groups
grouped["price"].mean()          # Mean price per sector
grouped.agg({
    "price": "mean",
    "shares": "sum",
    "volume": ["min", "max"]
})

# Multiple grouping
df.groupby(["sector", "year"])["revenue"].sum()
~~~

### Sorting

~~~python runnable
# Sort by column
df.sort_values("price")                     # Ascending
df.sort_values("price", ascending=False)    # Descending
df.sort_values(["sector", "price"])         # Multiple columns

# Sort by index
df.sort_index()
~~~

### Missing Data

~~~python runnable
# Check for missing
df.isna()                    # Boolean DataFrame
df.isna().sum()              # Count missing per column
df["price"].isna().any()     # Any missing in column?

# Handle missing
df.dropna()                  # Drop rows with any missing
df.dropna(subset=["price"])  # Drop if price is missing
df.fillna(0)                 # Fill with value
df.fillna(df.mean())         # Fill with column means
df["price"].fillna(method="ffill")  # Forward fill (last valid value)
~~~

### Time Series

~~~python runnable
# Parse dates
df["date"] = pd.to_datetime(df["date"])
df = df.set_index("date")

# Date-based selection
df["2024"]                   # All of 2024
df["2024-01"]                # January 2024
df["2024-01-15":"2024-01-31"]  # Date range

# Resampling
daily = df.resample("D").mean()      # Daily average
weekly = df.resample("W").last()     # Weekly (last value)
monthly = df.resample("M").ohlc()    # Monthly OHLC

# Rolling windows
df["MA20"] = df["close"].rolling(20).mean()    # 20-day moving average
df["volatility"] = df["return"].rolling(20).std()
~~~

---

## The Exercise

### Exercise 2.1: Load and Explore
~~~python exercise id="4.2.1"
# Download a CSV of historical stock prices (or create one)
# Explore: shape, columns, dtypes, head, tail, describe

# Sample data to create:
data = {
    "date": pd.date_range("2024-01-01", periods=100),
    "open": np.random.randn(100).cumsum() + 100,
    "high": np.random.randn(100).cumsum() + 102,
    "low": np.random.randn(100).cumsum() + 98,
    "close": np.random.randn(100).cumsum() + 100,
    "volume": np.random.randint(1000000, 5000000, 100)
}
df = pd.DataFrame(data)
df.to_csv("stock_prices.csv", index=False)
~~~

### Exercise 2.2: Calculate Technical Indicators
~~~python exercise id="4.2.2"
def add_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """
    Add common technical indicators:
    - daily_return: percentage change
    - MA20: 20-day moving average
    - MA50: 50-day moving average
    - volatility: 20-day rolling std of returns
    - RSI: Relative Strength Index (14-day)
    """
    pass
~~~

### Exercise 2.3: Sector Analysis
~~~python exercise id="4.2.3"
# Given DataFrame with columns: symbol, sector, price, market_cap
# Calculate:
# 1. Number of stocks per sector
# 2. Average price per sector
# 3. Total market cap per sector
# 4. Top 3 stocks by market cap in each sector
~~~

---

## The Gotchas

### Gotcha 1: SettingWithCopyWarning

```python
# This may or may not work as expected
df_filtered = df[df["price"] > 100]
df_filtered["new_col"] = 1  # Warning! May not modify df_filtered

# Explicit copy to be safe
df_filtered = df[df["price"] > 100].copy()
df_filtered["new_col"] = 1  # Works correctly
```

### Gotcha 2: loc vs iloc

```python
df = pd.DataFrame({"A": [1, 2, 3]}, index=["x", "y", "z"])

df.loc["x"]      # Selects by LABEL
df.iloc[0]       # Selects by POSITION (both return same row here)

df.loc[0]        # KeyError! No label "0"
df.iloc["x"]     # TypeError! Can't use string with iloc
```

### Gotcha 3: Chained Indexing

```python
# BAD - may not modify original DataFrame
df[df["price"] > 100]["price"] = 0

# GOOD - use loc
df.loc[df["price"] > 100, "price"] = 0
```

---

## Key Takeaways

1. DataFrame = labeled 2D data (like Excel but faster)
2. Use `loc` for label-based indexing, `iloc` for position-based
3. Boolean indexing for filtering: `df[df["col"] > value]`
4. GroupBy for aggregations by category
5. Rolling windows for time series calculations
6. Use `.copy()` to avoid SettingWithCopyWarning

---

## Next Lesson

Data is rarely clean. Next: **Data Cleaning**—handling missing values, duplicates, and inconsistent data.
